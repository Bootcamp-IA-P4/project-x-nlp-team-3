# üöÄ Project X: Detecci√≥n de Toxicidad en YouTube con IA 

[![Licencia: MIT](https://img.shields.io/badge/Licencia-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-20.10-blue.svg?logo=docker)](https://www.docker.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green.svg)](https://fastapi.tiangolo.com/)
[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Transformers-orange)](https://huggingface.co/transformers/)

Una soluci√≥n Full-Stack para el an√°lisis y detecci√≥n de toxicidad en comentarios de YouTube, utilizando un pipeline de MLOps desde la recolecci√≥n de datos hasta el despliegue de modelos de Machine Learning y Deep Learning.

Este proyecto implementa un sistema robusto capaz de clasificar comentarios de YouTube como "T√≥xicos" o "No T√≥xicos". Utiliza un enfoque dual, combinando un modelo de Machine Learning cl√°sico para una clasificaci√≥n r√°pida y un modelo Transformer avanzado para un an√°lisis de sentimiento m√°s profundo. Todo el sistema se sirve a trav√©s de una API RESTful de alto rendimiento y est√° completamente contenerizado con Docker para garantizar la portabilidad y escalabilidad.

---

##  Tabla de Contenidos

* [ Demo en Vivo y Documentaci√≥n](#-demo-en-vivo-y-documentaci√≥n)
* [‚ú® Caracter√≠sticas Principales](#-caracter√≠sticas-principales)
* [Ô∏è Arquitectura y Flujo del Proyecto](#Ô∏è-arquitectura-y-flujo-del-proyecto)
* [Ô∏è Stack Tecnol√≥gico](#Ô∏è-stack-tecnol√≥gico)
* [‚öôÔ∏è Instalaci√≥n y Puesta en Marcha](#Ô∏è-instalaci√≥n-y-puesta-en-marcha)
  * [Prerrequisitos](#prerrequisitos)
  * [Configuraci√≥n del Entorno](#configuraci√≥n-del-entorno)
  * [Ejecuci√≥n con Docker (Recomendado)](#ejecuci√≥n-con-docker-recomendado)
  * [Ejecuci√≥n Manual (Alternativa)](#ejecuci√≥n-manual-alternativa)
* [‚ñ∂Ô∏è C√≥mo Usar la Aplicaci√≥n](#Ô∏è-c√≥mo-usar-la-aplicaci√≥n)
* [ Modelos de Inteligencia Artificial](#-modelos-de-inteligencia-artificial)
  * [Enfoque 1: Machine Learning Supervisado (Clasificaci√≥n R√°pida)](#enfoque-1-machine-learning-supervisado-clasificaci√≥n-r√°pida)
  * [Enfoque 2: Modelo Transformer (An√°lisis Profundo)](#enfoque-2-modelo-transformer-an√°lisis-profundo)
* [ MLOps y Despliegue de Modelos](#-mlops-y-despliegue-de-modelos)
* [ Endpoints de la API](#-endpoints-de-la-api)
* [ CI/CD y Automatizaci√≥n](#-cicd-y-automatizaci√≥n)
* [ Contribuciones](#-contribuciones)
* [ Licencia](#-licencia)
* [ Agradecimientos](#-agradecimientos)

---

##  üåê Demo en Vivo y Documentaci√≥n

¬°Prueba la aplicaci√≥n y explora la documentaci√≥n t√©cnica completa!

* üåç **Documentaci√≥n en Vivo**: [(https://project-x-nlp-team-3.netlify.app)](https://resonant-hotteok-331ed1.netlify.app/)
* üìñ **Encyclop√©die Profonde (DeepWiki)**: Para b√∫squedas sem√°nticas y profundas en la base de c√≥digo del proyecto, visita nuestra DeepWiki: [https://deepwiki.com/Bootcamp-IA-P4/project-x-nlp-team-3](https://deepwiki.com/Bootcamp-IA-P4/project-x-nlp-team-3)

## ‚ú® Caracter√≠sticas Principales

* ü§ñ **Enfoque de Modelo Dual**:
  * **Clasificaci√≥n R√°pida**: Un modelo de ML (Naive Bayes + TF-IDF) para una detecci√≥n de toxicidad binaria y eficiente.
  * **An√°lisis Profundo**: Un modelo Transformer (DeBERTa) para un an√°lisis de sentimiento contextual (Positivo/Negativo).
* ‚ö° **API de Alto Rendimiento**: Construida con FastAPI, ofrece endpoints as√≠ncronos para servir los modelos de IA.
* üê≥ **Totalmente Contenerizado**: Usa Docker y Docker Compose para empaquetar y ejecutar los servicios de backend y frontend, garantizando la consistencia y facilidad de despliegue.
* üó£**Recolecci√≥n de Datos Reales**: Integra la API de YouTube v3 para obtener y analizar comentarios de cualquier video.
* üíæ **Persistencia de Datos**: Utiliza Supabase (PostgreSQL) para el almacenamiento de datos, gestionado a trav√©s del ORM SQLAlchemy.
* üîÑ **CI/CD para Documentaci√≥n**: Un flujo de trabajo de GitHub Actions construye y despliega autom√°ticamente la documentaci√≥n en GitHub Pages.
* üìö **Documentaci√≥n Exhaustiva**: Sitio de documentaci√≥n creado con MkDocs y Material for MkDocs, que detalla cada aspecto del proyecto.

## Ô∏èüèóÔ∏è Arquitectura y Flujo del Proyecto

El sistema est√° dise√±ado con componentes desacoplados que interact√∫an a trav√©s de APIs, siguiendo las mejores pr√°cticas de la ingenier√≠a de software y MLOps.


```mermaid
graph TD
    subgraph "Usuario Final & Desarrollador"
        U[‚Äç Usuario/Cliente API]
    end
    
    subgraph "Capa de Presentaci√≥n (Frontend)"
        F[ Cliente Web/UI]
    end
    
    subgraph "Contenedores de Servicios (Docker Compose)<img width="512" height="512" alt="social_15466088" src="https://github.com/user-attachments/assets/93ea1f02-3b69-4c3f-a95d-9376b97bca99" />
"
        %% Espacio para evitar que el t√≠tulo del subgr√°fico padre sea tapado
        
        subgraph "Servicio Backend"
            B[ Contenedor Backend] --> API[‚ö° FastAPI Server] ;
        end
        
        %% M√°s espacio para empujar el subgr√°fico de Frontend hacia abajo
        
        subgraph "Servicio Frontend"
            C[ Contenedor Frontend] --> F;
        end
    end
    
    subgraph "L√≥gica de Aplicaci√≥n (Dentro del Contenedor Backend)<img width="512" height="512" alt="image" src="https://github.com/user-attachments/assets/225086fa-1839-4247-ac11-dec5b9e16d7c" />"
        %% Espacio para empujar los nodos hacia abajo y evitar que el t√≠tulo del subgr√°fico sea tapado
        
        API --> RT[üîÑ Enrutador de API];
        RT --> P[üìù Preprocesamiento de Texto];
        RT --> DB[üíæ L√≥gica de Base de Datos];
        RT --> YT[üé¨ API de YouTube];
        P --> M1[ü§ñ Modelo ML Supervisado];
        P --> M2[üß† Modelo Transformer];
        DB --> SUPA[üêò Supabase/PostgreSQL];
        YT --> GAPI[<-- Google API -->];
    end
    
    
    subgraph "CI/CD & Infraestructura de C√≥digo (GitHub)<img width="512" height="512" alt="image" src="https://github.com/user-attachments/assets/de8cc36c-f755-4852-82e3-e856d85f4852" />"
        REPO[üêô Repositorio GitHub];
        REPO -- Push en 'main' --> GHA[üîÑ GitHub Actions];
        GHA -- Construye y Despliega --> DOCS[üìö Sitio de Documentaci√≥n];
    end
    
    U --> F;
    U -- Petici√≥n API --> B;
    F -- Petici√≥n HTTP --> B;
    B -- Respuesta JSON --> F;
    B -- Respuesta JSON --> U;
    
    style F fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#add,stroke:#333,stroke-width:2px
    style C fill:#add,stroke:#333,stroke-width:2px
    style GHA fill:#f0ad4e,stroke:#333,stroke-width:2px

```
----
## Ô∏è Stack Tecnol√≥gico

| √Årea                  | Tecnolog√≠a                         | Prop√≥sito                                                                 |
|-----------------------|------------------------------------|---------------------------------------------------------------------------|
| **Backend**           | `Python`, `FastAPI`, `Uvicorn`     | Creaci√≥n de la API RESTful de alto rendimiento.                           |
| **Frontend**          | `HTML5`, `CSS3`, `JavaScript`      | Interfaz de usuario para la interacci√≥n con el sistema.                   |
| **Contenerizaci√≥n**   | `Docker`, `Docker Compose`         | Empaquetar y orquestar los servicios de la aplicaci√≥n.                    |
| **Machine Learning**  | `Scikit-learn`, `Joblib`           | Entrenamiento y servicio del modelo de clasificaci√≥n r√°pida.              |
| **Deep Learning**     | `PyTorch`, `Transformers (Hugging Face)` | Carga y servicio del modelo de an√°lisis de sentimiento profundo.          |
| **Base de Datos**     | `Supabase (PostgreSQL)`, `SQLAlchemy` | Almacenamiento y gesti√≥n de los comentarios.                              |
| **Procesamiento de Texto** | `Pandas`, `NumPy`, `NLTK`, `Emoji` | Limpieza, preprocesamiento y manipulaci√≥n de datos de texto.              |
| **APIs Externas**     | `Google API Python Client`         | Interacci√≥n con la API de datos de YouTube.                               |
| **Documentaci√≥n**     | `MkDocs`, `Material for MkDocs`    | Creaci√≥n del sitio de documentaci√≥n t√©cnica.                              |
| **CI/CD**             | `GitHub Actions`                   | Automatizaci√≥n del despliegue de la documentaci√≥n.                        |
| **Experimentaci√≥n**   | `MLflow`                           | Seguimiento de experimentos, m√©tricas y modelos.                          |

## ‚öôÔ∏è Instalaci√≥n y Puesta en Marcha

Sigue estos pasos para tener el proyecto funcionando en tu entorno local.

### Prerrequisitos
* Git
* Python 3.12+
* Docker & Docker Compose
* Node.js & npm (solo para la ejecuci√≥n manual del frontend)

### Configuraci√≥n del Entorno
1. Clona el repositorio:

```bash
git clone https://github.com/jdomdev/project-x-nlp-team-3.git
cd project-x-nlp-team-3
```

2. Crea el archivo de entorno:
   Crea un archivo `.env` en la ra√≠z del proyecto y a√±ade tus credenciales. Debe contener, como m√≠nimo:

```bash
SUPABASE_URL="tu_url_de_supabase"
SUPABASE_KEY="tu_api_key_de_supabase"
YOUTUBE_API_KEY="tu_api_key_de_youtube"
DATABASE_URL="postgresql://usuario:password@host:puerto/basededatos"
```

### Ejecuci√≥n con Docker (Recomendado)
Este es el m√©todo m√°s sencillo y fiable. Levanta toda la aplicaci√≥n con un solo comando:

```bash
docker-compose up --build
```

* El Backend API estar√° disponible en http://localhost:8000.
* El Frontend estar√° disponible en http://localhost:5173.

### Ejecuci√≥n Manual (Alternativa)
#### Backend

```bash
# Activa el entorno virtual (si lo usas)
# source .venv/bin/activate

# Instala dependencias
pip install -r requirements.txt

# Inicia el servidor
uvicorn server.api.main:app --reload --host 0.0.0.0 --port 8000
```

#### Frontend

```bash
# Navega a la carpeta del cliente
cd client

# Instala dependencias
npm install

# Inicia el servidor de desarrollo
npm run dev
```

## ‚ñ∂Ô∏è C√≥mo Usar la Aplicaci√≥n
Una vez en marcha, puedes interactuar con el sistema de dos maneras:
1. **Interfaz Web**: Abre http://localhost:5173 en tu navegador para usar la interfaz gr√°fica.
2. **API Directa**: Env√≠a peticiones HTTP a los endpoints del backend en http://localhost:8000. Consulta la [documentaci√≥n de la API](https://project-x-nlp-team-3.netlify.app/api/endpoints) para m√°s detalles.

##  üìä Modelos de Inteligencia Artificial
Este proyecto utiliza un enfoque h√≠brido para ofrecer flexibilidad y rendimiento.

### Enfoque 1: Machine Learning Supervisado (Clasificaci√≥n R√°pida)
*   **Modelo**: `Multinomial Naive Bayes` optimizado.
*   **Tecnolog√≠a**: `Scikit-learn` y `Joblib` para la serializaci√≥n.
*   **Preprocesamiento**: Se aplica un pipeline que incluye `CountVectorizer` para la vectorizaci√≥n del texto, transformando los comentarios en una representaci√≥n num√©rica basada en la frecuencia de las palabras. El texto pasa por una limpieza exhaustiva (eliminaci√≥n de URLs, emojis, menciones, hashtags, puntuaci√≥n irrelevante) y lematizaci√≥n para normalizar las palabras a su forma base.
*   **Proceso**: Este modelo, ligero y eficiente, realiza una clasificaci√≥n binaria (`T√≥xico`/`No T√≥xico`). Es ideal para escenarios que requieren una respuesta r√°pida y un bajo consumo de recursos.
*   **Endpoint**: `/predict_ml`

### Enfoque 2: Modelo Transformer (An√°lisis Profundo)
*   **Modelo**: `DeBERTa` (Decoupled Attention Mechanism for Transformers) de Hugging Face.
*   **Tecnolog√≠a**: `PyTorch` y la librer√≠a `Transformers` de Hugging Face.
*   **Preprocesamiento**: Similar al modelo de ML, el texto se limpia y lematiza. Luego, se tokeniza utilizando `AutoTokenizer` (compatible con DeBERTa) para preparar la entrada para el modelo Transformer, asegurando que se manejen adecuadamente los matices contextuales del lenguaje.
*   **Proceso**: Este modelo de Deep Learning pre-entrenado es capaz de capturar relaciones contextuales complejas y matices sem√°nticos en el texto. Proporciona un an√°lisis de sentimiento m√°s detallado, ofreciendo una clasificaci√≥n (`Positivo`/`Negativo`) junto con un puntaje de confianza. Es adecuado para un an√°lisis m√°s profundo y preciso de comentarios individuales.
*   **Endpoint**: `/predict_nlp`

##  MLOps y Despliegue de Modelos
La integraci√≥n de los modelos en la API se realiza de manera robusta y escalable:
*   **Carga de Modelos**: Ambos modelos (`pipeline_multinomial_nb.pkl` y el modelo `DeBERTa` guardado en `model_transformer`) se cargan al iniciar la aplicaci√≥n FastAPI, asegurando que est√©n listos para la inferencia.
*   **Servicio de Predicciones**: FastAPI expone endpoints as√≠ncronos (`/predict_ml` y `/predict_nlp`) que permiten a los clientes interactuar con los modelos de manera eficiente.
*   **Contenerizaci√≥n**: La aplicaci√≥n completa, incluyendo los modelos y sus dependencias, se empaqueta en contenedores Docker. Esto garantiza un entorno de ejecuci√≥n consistente y facilita el despliegue en cualquier infraestructura compatible con Docker.

##  üîå Endpoints de la API
La API expone varios endpoints para la interacci√≥n. Aqu√≠ est√°n los principales:

| M√©todo | Endpoint                       | Descripci√≥n                                                                 |
|--------|--------------------------------|-----------------------------------------------------------------------------|
| `POST` | `/predict_ml`                  | Realiza una predicci√≥n de toxicidad r√°pida (T√≥xico/No T√≥xico) usando el modelo Naive Bayes. |
| `POST` | `/predict_nlp`                 | Realiza un an√°lisis de sentimiento profundo (Positivo/Negativo) usando el modelo DeBERTa. |
| `GET`  | `/comments/{video_id}`         | Obtiene comentarios de un video desde la base de datos.                     |
| `GET`  | `/youtube_comments/{video_id}` | Obtiene comentarios frescos directamente desde la API de YouTube.           |

Para una descripci√≥n completa de los cuerpos de las peticiones y las respuestas, visita la [Referencia de la API](https://project-x-nlp-team-3.netlify.app/api/endpoints).

##  üîÑ CI/CD y Automatizaci√≥n
* **Generaci√≥n de Documentaci√≥n**: Cada vez que se hace un push a la rama main, una GitHub Action se activa, instala MkDocs, construye el sitio de documentaci√≥n y lo despliega en GitHub Pages.
* **Gesti√≥n de Proyectos**: Se utiliza una Action para convertir autom√°ticamente las "Draft Issues" de un tablero de proyecto de GitHub en issues formales, agilizando la gesti√≥n de tareas.

##  Contribuciones
Las contribuciones son el coraz√≥n del c√≥digo abierto. Si deseas mejorar este proyecto, por favor sigue estos pasos:
1. Haz un Fork del repositorio.
2. Crea una rama para tu nueva funcionalidad (`git checkout -b feature/AmazingFeature`).
3. Haz Commit de tus cambios (`git commit -m 'Add some AmazingFeature'`).
4. Haz Push a tu rama (`git push origin feature/AmazingFeature`).
5. Abre una Pull Request.

##  Licencia
Este proyecto est√° bajo la Licencia MIT. Consulta el archivo LICENSE para m√°s detalles.

##  Agradecimientos
* Al equipo del Bootcamp de IA por su invaluable gu√≠a y apoyo.
* A la comunidad de Hugging Face por democratizar el acceso a los modelos Transformer.
* A los creadores de todas las librer√≠as y herramientas de c√≥digo abierto que han hecho posible este proyecto.


## üìä Retrospectiva Final de Proyecto üöÄ

¬°Felicidades por finalizar el proyecto de detecci√≥n de mensajes de odio en YouTube\! Es momento de reflexionar sobre todo el camino recorrido, aprender de nuestras experiencias y crecer como equipo.

**Objetivo:** Identificar qu√© funcion√≥ muy bien, qu√© podr√≠amos mejorar y qu√© aprendizajes clave nos llevamos para futuros proyectos.



| üßë‚Äçüíª **Miembro del Equipo** | üü¢ **Lo que Funcion√≥ Bien** (¬°√âxitos y Acerdos\!) ü•≥ | üü° **Lo que Podr√≠amos Mejorar** (Oportunidades de Crecimiento) ü§î | üî¥ **Aprendizajes Clave & Acciones a Futuro** (Lecciones Aprendidas) üß† |
| :----------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [mikewig](https://github.com/mikewig) (Fullstack Dev, DevOps) | Me ha gustado mucho la qu√≠mica con el equipo, todo ha ido de maravilla en cuanto al proyecto | Dir√≠a que seleccionar bien el rol de cada uno, ya que al principio escog√≠ un rol pero termine haciendo otras cosas adem√°s de eso | Aprend√≠ un poco de front-end y back-end, lo cual me alegra ya que sobre todo en front no tenia mucho conocimiento acerca de esto |
| [Jorgeluuu](https://github.com/Jorgeluuu) (ML Engineer) | Me ha sorprendido gratamente la sinergia de todo el equipo, la coordinaci√≥n que hemos tenido en todo momento para completar cada objetivo. | Siento que nos hemos compenetrado muy bien entre todos, abarcando todos los puntos claves del proyecto gracias a la definici√≥n de roles que hemos tenido. Por lo que no siento nada en lo que hacer hincapi√© | Me quedo con las Pull Request, ya no solo para saber lo que ha ido haciendo cada uno, sino a la hora de realizar los mergeos de ramas, ya sea de una misma rama o a distintas ramas. |
| [abbyenredes](https://github.com/abbyenredes) (Data Analyst, DevOps) | Buena sinergia en el equipo, completamos la mayor√≠a de objetivos | No siento que haya nada relevante, me parece que abarcamos bien cada uno el proyecto con roles muy bien definidos | Las PR, son una maravilla a la hora de hacer merge|
| [mr-melenas](https://github.com/mr-melenas) (ML Engineer, DevOps) |la velocidad para conseguir los objetivos de forma continuada |un poco mas de tiempo para haber experimentado con trnasformers mas complejos | |
| [jdomdev](https://github.com/jdomdev) (Scrum Master, BackendDev) | La implementaci√≥n de m√≥dulos del proyecto y su integraci√≥n | Haber llevado un registro m√°s detallado de los Sprints | Uso e implementaci√≥n de Tranformers, despliegue documentaci√≥n y Pipeline |

