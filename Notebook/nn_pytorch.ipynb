{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb09d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import requests\n",
    "from io import BytesIO, StringIO\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "673e7767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Downloading data from GitHub...\n",
      "üìä Reading CSV file...\n",
      "‚úÖ Data downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "GITHUB_CLEAN_URL = \"https://raw.githubusercontent.com/Bootcamp-IA-P4/project-x-nlp-team-3/feature/models/Data/fusion30.csv\"\n",
    "\n",
    "def load_comments_data_from_github(url):\n",
    "    \"\"\"\n",
    "    Downloading and processing comments data from GitHub repository.\n",
    "    \"\"\"\n",
    "    print(\"üîó Downloading data from GitHub...\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        print(\"üìä Reading CSV file...\")\n",
    "\n",
    "        df = pd.read_csv(StringIO(response.text), sep=';')\n",
    "\n",
    "        print(\"‚úÖ Data downloaded successfully!\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while downloading data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Creating dataframe from GitHub URL\n",
    "df = load_comments_data_from_github(GITHUB_CLEAN_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf6521",
   "metadata": {},
   "source": [
    "Definir la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69364140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar el texto usando TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # Limitamos a 1000 caracter√≠sticas\n",
    "X = vectorizer.fit_transform(df['text']).toarray()\n",
    "y = df['label']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir a tensores de PyTorch\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train.values)\n",
    "y_test = torch.LongTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la red neuronal\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.fc3 = nn.Linear(hidden_dim//2, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_dim//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3673fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar hiperpar√°metros\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = len(torch.unique(y_train))\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed5e25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/919852534155930550', creation_time=1751878783567, experiment_id='919852534155930550', last_update_time=1751878783567, lifecycle_stage='active', name='Neural_Network_Model', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear data loaders\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Configurar MLflow antes de iniciar el experimento\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Neural_Network_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e3aa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50]\n",
      "Loss: 0.2075\n",
      "Train Accuracy: 0.9685\n",
      "Test Accuracy: 0.7357\n",
      "\n",
      "Epoch [20/50]\n",
      "Loss: 0.1305\n",
      "Train Accuracy: 0.9865\n",
      "Test Accuracy: 0.7312\n",
      "\n",
      "Epoch [30/50]\n",
      "Loss: 0.1003\n",
      "Train Accuracy: 0.9907\n",
      "Test Accuracy: 0.7341\n",
      "\n",
      "Epoch [40/50]\n",
      "Loss: 0.0876\n",
      "Train Accuracy: 0.9915\n",
      "Test Accuracy: 0.7319\n",
      "\n",
      "Epoch [50/50]\n",
      "Loss: 0.0820\n",
      "Train Accuracy: 0.9928\n",
      "Test Accuracy: 0.7327\n",
      "\n",
      "üèÉ View run PyTorch_NN_Training at: http://localhost:5000/#/experiments/919852534155930550/runs/9c75a722537242a78dec77e2166056f5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/919852534155930550\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "with mlflow.start_run(run_name=\"PyTorch_NN_Training\"):\n",
    "    # Registrar hiperpar√°metros\n",
    "    mlflow.log_params({\n",
    "        \"input_dim\": input_dim,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"output_dim\": output_dim,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"dropout_rate\": dropout_rate\n",
    "    })\n",
    "    \n",
    "    # Inicializar modelo, criterio y optimizador\n",
    "    model = SimpleNN(input_dim, hidden_dim, output_dim, dropout_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Evaluaci√≥n\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_outputs = model(X_train)\n",
    "            train_preds = torch.argmax(train_outputs, dim=1)\n",
    "            train_acc = accuracy_score(y_train, train_preds)\n",
    "            \n",
    "            test_outputs = model(X_test)\n",
    "            test_preds = torch.argmax(test_outputs, dim=1)\n",
    "            test_acc = accuracy_score(y_test, test_preds)\n",
    "        \n",
    "        # Registrar m√©tricas\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": avg_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"test_accuracy\": test_acc\n",
    "        }, step=epoch)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "            print(f\"Test Accuracy: {test_acc:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc1daf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M√©tricas de Entrenamiento:\n",
      "Accuracy: 0.9928\n",
      "\n",
      "Reporte de Clasificaci√≥n (Entrenamiento):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     10856\n",
      "           1       0.99      0.99      0.99     13120\n",
      "\n",
      "    accuracy                           0.99     23976\n",
      "   macro avg       0.99      0.99      0.99     23976\n",
      "weighted avg       0.99      0.99      0.99     23976\n",
      "\n",
      "\n",
      "M√©tricas de Prueba:\n",
      "Accuracy: 0.7327\n",
      "\n",
      "Reporte de Clasificaci√≥n (Prueba):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70      2646\n",
      "           1       0.77      0.74      0.76      3348\n",
      "\n",
      "    accuracy                           0.73      5994\n",
      "   macro avg       0.73      0.73      0.73      5994\n",
      "weighted avg       0.73      0.73      0.73      5994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n final del modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # M√©tricas de entrenamiento\n",
    "    train_outputs = model(X_train)\n",
    "    train_preds = torch.argmax(train_outputs, dim=1)\n",
    "    train_acc = accuracy_score(y_train, train_preds)\n",
    "    train_report = classification_report(y_train, train_preds)\n",
    "    \n",
    "    # M√©tricas de prueba\n",
    "    test_outputs = model(X_test)\n",
    "    test_preds = torch.argmax(test_outputs, dim=1)\n",
    "    test_acc = accuracy_score(y_test, test_preds)\n",
    "    test_report = classification_report(y_test, test_preds)\n",
    "\n",
    "    # Imprimir m√©tricas por pantalla\n",
    "    print(\"\\nM√©tricas de Entrenamiento:\")\n",
    "    print(f\"Accuracy: {train_acc:.4f}\")\n",
    "    print(\"\\nReporte de Clasificaci√≥n (Entrenamiento):\")\n",
    "    print(train_report)\n",
    "    \n",
    "    print(\"\\nM√©tricas de Prueba:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(\"\\nReporte de Clasificaci√≥n (Prueba):\")\n",
    "    print(test_report)\n",
    "    \n",
    "    # Registrar m√©tricas en MLflow\n",
    "    mlflow.log_metric(\"final_train_accuracy\", train_acc)\n",
    "    mlflow.log_metric(\"final_test_accuracy\", test_acc)\n",
    "    \n",
    "    # Guardar los reportes de clasificaci√≥n\n",
    "    mlflow.log_text(train_report, \"train_classification_report.txt\")\n",
    "    mlflow.log_text(test_report, \"test_classification_report.txt\")\n",
    "    \n",
    "    # Calcular y registrar m√©tricas adicionales por clase\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    # M√©tricas detalladas para conjunto de prueba\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_test, test_preds)\n",
    "    \n",
    "    for i, (p, r, f) in enumerate(zip(precision, recall, f1)):\n",
    "        mlflow.log_metrics({\n",
    "            f\"class_{i}_precision\": p,\n",
    "            f\"class_{i}_recall\": r,\n",
    "            f\"class_{i}_f1\": f\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c56797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pickle\n",
    "import pickle\n",
    "\n",
    "# Guardar el modelo en formato .pkl\n",
    "with open('../Models/pytorch/pytorch_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Tambi√©n guardar el vectorizador para futuros usos\n",
    "with open('../Models/pytorch/pytorch_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
