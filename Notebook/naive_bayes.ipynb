{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import requests\n",
    "from io import BytesIO, StringIO\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import joblib\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Downloading data from GitHub...\n",
      "üìä Reading CSV file...\n",
      "‚úÖ Data downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "GITHUB_CLEAN_URL = \"https://raw.githubusercontent.com/Bootcamp-IA-P4/Bootcamp-IA-P4-project-x-nlp-team-3/feature/eda/Data/comments_data_clean.csv\"\n",
    "\n",
    "def load_comments_data_from_github(url):\n",
    "    \"\"\"\n",
    "    Downloading and processing comments data from GitHub repository.\n",
    "    \"\"\"\n",
    "    print(\"üîó Downloading data from GitHub...\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        print(\"üìä Reading CSV file...\")\n",
    "\n",
    "        df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "        print(\"‚úÖ Data downloaded successfully!\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while downloading data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Creating dataframe from GitHub URL\n",
    "df = load_comments_data_from_github(GITHUB_CLEAN_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor alpha MultinomialNB: 1.0\n",
      "Mejor F1 MultinomialNB: 0.6795\n",
      "Mejor alpha BernoulliNB: 0.5\n",
      "Mejor F1 BernoulliNB: 0.6830\n",
      "Mejor var_smoothing GaussianNB: 1e-09\n",
      "Mejor F1 GaussianNB: 0.5430\n",
      "MultinomialNB optimizado entrenado correctamente:\n",
      "Accuracy: 0.7650 | F1: 0.7649 | Recall: 0.7650 | Precision: 0.7713\n",
      "MultinomialNB F1 Entrenamiento: 0.9410 | F1 Prueba: 0.7649\n",
      "BernoulliNB optimizado entrenado correctamente:\n",
      "Accuracy: 0.7400 | F1: 0.7398 | Recall: 0.7400 | Precision: 0.7469\n",
      "BernoulliNB F1 Entrenamiento: 0.9410 | F1 Prueba: 0.7649\n",
      "GaussianNB optimizado entrenado correctamente:\n",
      "Accuracy: 0.6000 | F1: 0.5897 | Recall: 0.6000 | Precision: 0.6006\n",
      "GaussianNB F1 Entrenamiento: 0.9023 | F1 Prueba: 0.5897\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento\n",
    "TEXT_COLUMN = 'Text'      # Cambia si tu columna de texto tiene otro nombre\n",
    "TARGET_COLUMN = 'IsToxic' # Cambia si tu columna objetivo tiene otro nombre\n",
    "\n",
    "# Vectorizaci√≥n del texto\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[TEXT_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "# Divisi√≥n de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optimizaci√≥n de hiperpar√°metros para MultinomialNB y BernoulliNB\n",
    "alphas = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "# MultinomialNB\n",
    "param_grid_mnb = {'alpha': alphas}\n",
    "grid_mnb = GridSearchCV(MultinomialNB(), param_grid_mnb, cv=5, scoring='f1_weighted')\n",
    "grid_mnb.fit(X_train, y_train)\n",
    "best_alpha_mnb = grid_mnb.best_params_['alpha']\n",
    "print(f\"Mejor alpha MultinomialNB: {best_alpha_mnb}\")\n",
    "print(f\"Mejor F1 MultinomialNB: {grid_mnb.best_score_:.4f}\")\n",
    "\n",
    "# BernoulliNB\n",
    "param_grid_bnb = {'alpha': alphas}\n",
    "grid_bnb = GridSearchCV(BernoulliNB(), param_grid_bnb, cv=5, scoring='f1_weighted')\n",
    "grid_bnb.fit(X_train, y_train)\n",
    "best_alpha_bnb = grid_bnb.best_params_['alpha']\n",
    "print(f\"Mejor alpha BernoulliNB: {best_alpha_bnb}\")\n",
    "print(f\"Mejor F1 BernoulliNB: {grid_bnb.best_score_:.4f}\")\n",
    "\n",
    "# GaussianNB (requiere arrays densos)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "param_grid_gnb = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]}\n",
    "grid_gnb = GridSearchCV(GaussianNB(), param_grid_gnb, cv=5, scoring='f1_weighted')\n",
    "grid_gnb.fit(X_train_dense, y_train)\n",
    "best_vs_gnb = grid_gnb.best_params_['var_smoothing']\n",
    "print(f\"Mejor var_smoothing GaussianNB: {best_vs_gnb}\")\n",
    "print(f\"Mejor F1 GaussianNB: {grid_gnb.best_score_:.4f}\")\n",
    "\n",
    "# Entrenamiento y evaluaci√≥n final con los mejores hiperpar√°metros\n",
    "with mlflow.start_run(run_name=\"NaiveBayes_Models_Multinominal_Optimizado\"):\n",
    "    mnb = MultinomialNB(alpha=best_alpha_mnb)\n",
    "    mnb.fit(X_train, y_train)\n",
    "    y_pred_mnb = mnb.predict(X_test)\n",
    "    acc_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "    f1_score_mnb = f1_score(y_test, y_pred_mnb, average='weighted')\n",
    "    recall_mnb = recall_score(y_test, y_pred_mnb, average='weighted')\n",
    "    precision_mnb = precision_score(y_test, y_pred_mnb, average='weighted')\n",
    "    print(\"MultinomialNB optimizado entrenado correctamente:\")\n",
    "    print(f\"Accuracy: {acc_mnb:.4f} | F1: {f1_score_mnb:.4f} | Recall: {recall_mnb:.4f} | Precision: {precision_mnb:.4f}\")\n",
    "\n",
    "    # Evaluaci√≥n en entrenamiento y prueba para MultinomialNB\n",
    "    train_pred_mnb = mnb.predict(X_train)\n",
    "    test_pred_mnb = mnb.predict(X_test)\n",
    "    train_f1_mnb = f1_score(y_train, train_pred_mnb, average='weighted')\n",
    "    test_f1_mnb = f1_score(y_test, test_pred_mnb, average='weighted')\n",
    "    overfit_f1_mnb = train_f1_mnb - test_f1_mnb\n",
    "    print(f\"MultinomialNB F1 Entrenamiento: {train_f1_mnb:.4f} | F1 Prueba: {test_f1_mnb:.4f}\")\n",
    "\n",
    "    mlflow.log_param(\"alpha\", best_alpha_mnb)\n",
    "    mlflow.log_metric(\"accuracy\", acc_mnb)\n",
    "    mlflow.log_metric(\"f1_score\", f1_score_mnb)\n",
    "    mlflow.log_metric(\"recall\", recall_mnb)\n",
    "    mlflow.log_metric(\"precision\", precision_mnb)\n",
    "    mlflow.log_metric(\"overfit_f1\", overfit_f1_mnb)\n",
    "\n",
    "with mlflow.start_run(run_name=\"NaiveBayes_Models_Bernoulli_Optimizado\"):\n",
    "    bnb = BernoulliNB(alpha=best_alpha_bnb)\n",
    "    bnb.fit(X_train, y_train)\n",
    "    y_pred_bnb = bnb.predict(X_test)\n",
    "    acc_bnb = accuracy_score(y_test, y_pred_bnb)\n",
    "    f1_score_bnb = f1_score(y_test, y_pred_bnb, average='weighted')\n",
    "    recall_bnb = recall_score(y_test, y_pred_bnb, average='weighted')\n",
    "    precision_bnb = precision_score(y_test, y_pred_bnb, average='weighted')\n",
    "    print(\"BernoulliNB optimizado entrenado correctamente:\")\n",
    "    print(f\"Accuracy: {acc_bnb:.4f} | F1: {f1_score_bnb:.4f} | Recall: {recall_bnb:.4f} | Precision: {precision_bnb:.4f}\")\n",
    "\n",
    "    train_pred_bnb = bnb.predict(X_train)\n",
    "    test_pred_bnb = bnb.predict(X_test)\n",
    "    train_f1_bnb = f1_score(y_train, train_pred_bnb, average='weighted')\n",
    "    test_f1_bnb = f1_score(y_test, test_pred_bnb, average='weighted')\n",
    "    overfit_f1_bnb = train_f1_bnb - test_f1_bnb\n",
    "    print(f\"BernoulliNB F1 Entrenamiento: {train_f1_mnb:.4f} | F1 Prueba: {test_f1_mnb:.4f}\")\n",
    "\n",
    "    mlflow.log_param(\"alpha\", best_alpha_bnb)\n",
    "    mlflow.log_metric(\"accuracy\", acc_bnb)\n",
    "    mlflow.log_metric(\"f1_score\", f1_score_bnb)\n",
    "    mlflow.log_metric(\"recall\", recall_bnb)\n",
    "    mlflow.log_metric(\"precision\", precision_bnb)\n",
    "    mlflow.log_metric(\"overfit_f1\", overfit_f1_bnb)\n",
    "\n",
    "with mlflow.start_run(run_name=\"NaiveBayes_Models_Gaussian_Optimizado\"):\n",
    "    gnb = GaussianNB(var_smoothing=best_vs_gnb)\n",
    "    gnb.fit(X_train_dense, y_train)\n",
    "    y_pred_gnb = gnb.predict(X_test_dense)\n",
    "    acc_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "    f1_score_gnb = f1_score(y_test, y_pred_gnb, average='weighted')\n",
    "    recall_gnb = recall_score(y_test, y_pred_gnb, average='weighted')\n",
    "    precision_gnb = precision_score(y_test, y_pred_gnb, average='weighted')\n",
    "    print(\"GaussianNB optimizado entrenado correctamente:\")\n",
    "    print(f\"Accuracy: {acc_gnb:.4f} | F1: {f1_score_gnb:.4f} | Recall: {recall_gnb:.4f} | Precision: {precision_gnb:.4f}\")\n",
    "\n",
    "    #Evaluaci√≥n en entrenamiento y prueba para GaussianNB\n",
    "    train_pred_gnb = gnb.predict(X_train_dense)\n",
    "    test_pred_gnb = gnb.predict(X_test_dense)\n",
    "    train_f1_gnb = f1_score(y_train, train_pred_gnb, average='weighted')\n",
    "    test_f1_gnb = f1_score(y_test, test_pred_gnb, average='weighted')\n",
    "    overfit_f1_gnb = train_f1_gnb - test_f1_gnb\n",
    "    print(f\"GaussianNB F1 Entrenamiento: {train_f1_gnb:.4f} | F1 Prueba: {test_f1_gnb:.4f}\")\n",
    "\n",
    "    mlflow.log_param(\"var_smoothing\", best_vs_gnb)\n",
    "    mlflow.log_metric(\"accuracy\", acc_gnb)\n",
    "    mlflow.log_metric(\"f1_score\", f1_score_gnb)\n",
    "    mlflow.log_metric(\"recall\", recall_gnb)\n",
    "    mlflow.log_metric(\"precision\", precision_gnb)\n",
    "    mlflow.log_metric(\"overfit_f1\", overfit_f1_gnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline MultinomialNB guardado como pipeline_multinomial_nb.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Crear un pipeline que incluya la vectorizaci√≥n y el modelo MultinomialNB optimizado\n",
    "pipeline_mnb = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB(alpha=best_alpha_mnb))\n",
    "])\n",
    "\n",
    "# Entrenar el pipeline con los datos originales de texto\n",
    "pipeline_mnb.fit(df[TEXT_COLUMN], df[TARGET_COLUMN])\n",
    "\n",
    "# Guardar el pipeline entrenado en un archivo .pkl\n",
    "joblib.dump(pipeline_mnb, 'pipeline_multinomial_nb.pkl')\n",
    "print(\"Pipeline MultinomialNB guardado como pipeline_multinomial_nb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo MultinomialNB guardado como multinomial_nb_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Entrena el modelo MultinomialNB con los mejores hiperpar√°metros (ajusta si usaste GridSearchCV)\n",
    "best_mnb = MultinomialNB(alpha=1.0)  # Cambia alpha si tienes el mejor valor de GridSearchCV\n",
    "best_mnb.fit(X_train, y_train)\n",
    "\n",
    "# Guarda el modelo entrenado en un archivo .pkl\n",
    "joblib.dump(best_mnb, 'multinomial_nb_model.pkl')\n",
    "print(\"Modelo MultinomialNB guardado como multinomial_nb_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
