{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de Comentarios Tóxicos con BERT\n",
    "\n",
    "Este notebook implementa un modelo avanzado para la detección de comentarios tóxicos utilizando BERT (Bidirectional Encoder Representations from Transformers). Mejoraremos el preprocesamiento de texto y aplicaremos técnicas de aumento de datos para mejorar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import emoji\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Definir una ruta específica para los datos de NLTK\n",
    "nltk_data_path = os.path.join(os.path.expanduser('~'), 'nltk_data')\n",
    "os.makedirs(nltk_data_path, exist_ok=True)\n",
    "\n",
    "# Descargar los recursos especificando la ruta\n",
    "nltk.download('punkt', download_dir=nltk_data_path)\n",
    "nltk.download('stopwords', download_dir=nltk_data_path)\n",
    "nltk.download('wordnet', download_dir=nltk_data_path)\n",
    "nltk.download('omw-1.4', download_dir=nltk_data_path)\n",
    "\n",
    "# Añadir la ruta al path de NLTK\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "# Configurar estilo de visualización\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Verificar si CUDA está disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando dispositivo: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploración de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('../Data/fusion30.csv', sep=';')\n",
    "\n",
    "# Mostrar información básica\n",
    "print(f'Forma del dataset: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinar la distribución de clases\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='result', data=df)\n",
    "plt.title('Distribución de Comentarios Tóxicos vs No Tóxicos')\n",
    "plt.xlabel('Clase (1=Tóxico, 0=No Tóxico)')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar porcentajes\n",
    "class_counts = df['result'].value_counts(normalize=True) * 100\n",
    "print(f'Porcentaje de comentarios tóxicos: {class_counts[1]:.2f}%')\n",
    "print(f'Porcentaje de comentarios no tóxicos: {class_counts[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer el texto de la columna 'Record'\n",
    "# El texto está entre comillas triples, así que necesitamos limpiarlo\n",
    "df['text'] = df['Record'].str.strip('\"\"\"').str.strip()\n",
    "\n",
    "# Verificar la longitud de los comentarios\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df, x='text_length', hue='result', bins=50, kde=True)\n",
    "plt.title('Distribución de la Longitud de Comentarios por Clase')\n",
    "plt.xlabel('Longitud del Texto')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas descriptivas de la longitud del texto\n",
    "print('Estadísticas de longitud de texto:')\n",
    "print(df.groupby('result')['text_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento Avanzado de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    Función para realizar una limpieza avanzada del texto:\n",
    "    - Elimina URLs\n",
    "    - Convierte emojis a texto\n",
    "    - Elimina menciones (@usuario)\n",
    "    - Elimina hashtags (#tema)\n",
    "    - Elimina puntuación irrelevante\n",
    "    - Normaliza espacios\n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Eliminar URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
    " \n",
    "    # Convertir emojis a texto\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    # Eliminar menciones (@usuario)\n",
    "    text = re.sub(r'@\\w+', ' ', text)\n",
    "    \n",
    "    # Eliminar hashtags (#tema) pero mantener el texto del hashtag\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Eliminar caracteres repetidos (más de 2 veces)\n",
    "    text = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', text)\n",
    "    \n",
    "    # Eliminar puntuación irrelevante pero mantener algunos signos importantes\n",
    "    # Mantenemos '?' y '!' ya que pueden indicar tono emocional\n",
    "    punct_to_remove = string.punctuation.replace('?', '').replace('!', '')\n",
    "    text = ''.join([char if char not in punct_to_remove else ' ' for char in text])\n",
    "    \n",
    "    # Normalizar espacios múltiples\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    '''\n",
    "    Función para lematizar el texto usando WordNetLemmatizer de NLTK.\n",
    "    La lematización reduce las palabras a su forma base (lema) teniendo en cuenta su contexto,\n",
    "    lo que puede mejorar el rendimiento en comparación con el stemming.\n",
    "    '''\n",
    "    if not isinstance(text, str) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    # Tokenizar el texto\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Inicializar el lematizador\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Obtener stopwords en inglés\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Lematizar cada token y eliminar stopwords\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Unir los tokens lematizados\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limpieza y lematización al texto\n",
    "print('Aplicando preprocesamiento avanzado...')\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "df['lemmatized_text'] = df['cleaned_text'].apply(lemmatize_text)\n",
    "\n",
    "# Mostrar ejemplos de texto original vs procesado\n",
    "examples = df[['text', 'cleaned_text', 'lemmatized_text']].head(5)\n",
    "for i, row in examples.iterrows():\n",
    "    print(f'\nEjemplo {i+1}:\n')\n",
    "    print(f'Original: {row['text']}')\n",
    "    print(f'Limpiado: {row['cleaned_text']}')\n",
    "    print(f'Lematizado: {row['lemmatized_text']}')\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aumento de Datos con NLP Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_text(text, num_samples=1):\n",
    "    '''\n",
    "    Función para aumentar datos textuales usando técnicas de NLP Augment.\n",
    "    Aplica varias técnicas de aumento como sustitución de sinónimos,\n",
    "    inserción aleatoria, intercambio de palabras, etc.\n",
    "    '''\n",
    "    if not isinstance(text, str) or text == '':\n",
    "        return []\n",
    "    \n",
    "    augmented_texts = []\n",
    "    \n",
    "    # 1. Sustitución de sinónimos\n",
    "    aug_synonym = naw.SynonymAug(aug_src='wordnet')\n",
    "    \n",
    "    # 2. Inserción aleatoria de palabras\n",
    "    aug_insert = naw.RandomWordAug(action='insert')\n",
    "    \n",
    "    # 3. Intercambio aleatorio de palabras\n",
    "    aug_swap = naw.RandomWordAug(action='swap')\n",
    "    \n",
    "    # 4. Eliminación aleatoria de palabras\n",
    "    aug_delete = naw.RandomWordAug(action='delete')\n",
    "    \n",
    "    # Lista de aumentadores\n",
    "    augmenters = [aug_synonym, aug_insert, aug_swap, aug_delete]\n",
    "    \n",
    "    # Generar muestras aumentadas\n",
    "    for _ in range(num_samples):\n",
    "        # Seleccionar un aumentador aleatorio\n",
    "        aug = np.random.choice(augmenters)\n",
    "        \n",
    "        try:\n",
    "            # Aplicar aumento\n",
    "            augmented_text = aug.augment(text)\n",
    "            augmented_texts.append(augmented_text)\n",
    "        except:\n",
    "            # Si falla, usar el texto original\n",
    "            augmented_texts.append(text)\n",
    "    \n",
    "    return augmented_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar aumento de datos solo a la clase minoritaria para balancear el dataset\n",
    "# Identificar la clase minoritaria\n",
    "minority_class = 0 if class_counts[0] < class_counts[1] else 1\n",
    "majority_class = 1 if minority_class == 0 else 0\n",
    "\n",
    "print(f'Clase minoritaria: {minority_class}')\n",
    "print(f'Clase mayoritaria: {majority_class}')\n",
    "\n",
    "# Calcular cuántas muestras necesitamos generar para balancear las clases\n",
    "minority_samples = df[df['result'] == minority_class]\n",
    "majority_samples = df[df['result'] == majority_class]\n",
    "\n",
    "num_minority = len(minority_samples)\n",
    "num_majority = len(majority_samples)\n",
    "\n",
    "print(f'Muestras de clase minoritaria: {num_minority}')\n",
    "print(f'Muestras de clase mayoritaria: {num_majority}')\n",
    "\n",
    "# Determinar cuántas muestras aumentadas necesitamos por texto minoritario\n",
    "samples_needed = num_majority - num_minority\n",
    "samples_per_text = max(1, samples_needed // num_minority)\n",
    "\n",
    "print(f'Muestras necesarias para balancear: {samples_needed}')\n",
    "print(f'Muestras a generar por texto: {samples_per_text}')\n",
    "\n",
    "# Generar muestras aumentadas para la clase minoritaria\n",
    "print('Generando muestras aumentadas...')\n",
    "\n",
    "augmented_texts = []\n",
    "augmented_labels = []\n",
    "\n",
    "# Limitar el número de muestras a aumentar para evitar tiempos de ejecución largos\n",
    "max_samples_to_augment = min(num_minority, 1000)\n",
    "\n",
    "for i, row in tqdm(minority_samples.head(max_samples_to_augment).iterrows(), total=max_samples_to_augment):\n",
    "    text = row['lemmatized_text']\n",
    "    label = row['result']\n",
    "    \n",
    "    # Generar textos aumentados\n",
    "    aug_texts = augment_text(text, num_samples=samples_per_text)\n",
    "    \n",
    "    # Agregar a las listas\n",
    "    augmented_texts.extend(aug_texts)\n",
    "    augmented_labels.extend([label] * len(aug_texts))\n",
    "\n",
    "# Crear DataFrame con los datos aumentados\n",
    "augmented_df = pd.DataFrame({\n",
    "    'lemmatized_text': augmented_texts,\n",
    "    'result': augmented_labels\n",
    "})\n",
    "\n",
    "print(f'Muestras aumentadas generadas: {len(augmented_df)}')\n",
    "\n",
    "# Combinar el DataFrame original con el aumentado\n",
    "combined_df = pd.concat([\n",
    "    df[['lemmatized_text', 'result']],\n",
    "    augmented_df\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f'Total de muestras después del aumento: {len(combined_df)}')\n",
    "\n",
    "# Verificar la distribución de clases después del aumento\n",
    "new_class_counts = combined_df['result'].value_counts(normalize=True) * 100\n",
    "print(f'Nueva distribución de clases:\n{new_class_counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparación de Datos para BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
    "X = combined_df['lemmatized_text'].values\n",
    "y = combined_df['result'].values\n",
    "\n",
    "# Primero dividimos en entrenamiento+validación y prueba\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Luego dividimos entrenamiento+validación en entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.1, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f'Conjunto de entrenamiento: {len(X_train)} muestras')\n",
    "print(f'Conjunto de validación: {len(X_val)} muestras')\n",
    "print(f'Conjunto de prueba: {len(X_test)} muestras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el tokenizador de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Definir la longitud máxima de secuencia\n",
    "# BERT tiene un límite de 512 tokens, pero podemos usar un valor menor si nuestros textos son más cortos\n",
    "MAX_LEN = 128\n",
    "\n",
    "class ToxicCommentsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenizar el texto\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets\n",
    "train_dataset = ToxicCommentsDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
    "val_dataset = ToxicCommentsDataset(X_val, y_val, tokenizer, MAX_LEN)\n",
    "test_dataset = ToxicCommentsDataset(X_test, y_test, tokenizer, MAX_LEN)\n",
    "\n",
    "# Definir tamaño de batch\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Crear dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modelo BERT para Clasificación de Comentarios Tóxicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo BERT preentrenado\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2,  # Clasificación binaria: tóxico o no tóxico\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Mover el modelo al dispositivo (GPU si está disponible)\n",
    "model = model.to(device)\n",
    "\n",
    "# Definir el optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "# Número de épocas de entrenamiento\n",
    "EPOCHS = 4\n",
    "\n",
    "# Calcular el número total de pasos de entrenamiento\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# Crear el planificador de tasa de aprendizaje\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    '''\n",
    "    Función para entrenar el modelo durante una época\n",
    "    '''\n",
    "    # Poner el modelo en modo de entrenamiento\n",
    "    model.train()\n",
    "    \n",
    "    # Inicializar variables para seguimiento\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    \n",
    "    # Iterar sobre los batches\n",
    "    for batch in tqdm(dataloader, desc='Entrenando'):\n",
    "        # Extraer datos del batch\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Limpiar gradientes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        # Obtener pérdida y logits\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Actualizar parámetros\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Acumular pérdida\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Obtener predicciones\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        \n",
    "        # Guardar predicciones y etiquetas reales\n",
    "        predictions.extend(preds.cpu().tolist())\n",
    "        actual_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    # Calcular métricas\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    f1 = f1_score(actual_labels, predictions)\n",
    "    precision = precision_score(actual_labels, predictions)\n",
    "    recall = recall_score(actual_labels, predictions)\n",
    "    \n",
    "    return avg_loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    '''\n",
    "    Función para evaluar el modelo\n",
    "    '''\n",
    "    # Poner el modelo en modo de evaluación\n",
    "    model.eval()\n",
    "    \n",
    "    # Inicializar variables para seguimiento\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    \n",
    "    # Desactivar cálculo de gradientes\n",
    "    with torch.no_grad():\n",
    "        # Iterar sobre los batches\n",
    "        for batch in tqdm(dataloader, desc='Evaluando'):\n",
    "            # Extraer datos del batch\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            # Obtener pérdida y logits\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Acumular pérdida\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Obtener predicciones\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            \n",
    "            # Guardar predicciones y etiquetas reales\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    # Calcular métricas\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    f1 = f1_score(actual_labels, predictions)\n",
    "    precision = precision_score(actual_labels, predictions)\n",
    "    recall = recall_score(actual_labels, predictions)\n",
    "    \n",
    "    # Calcular matriz de confusión\n",
    "    conf_matrix = confusion_matrix(actual_labels, predictions)\n",
    "    \n",
    "    return avg_loss, accuracy, f1, precision, recall, conf_matrix, predictions, actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "print('Iniciando entrenamiento del modelo BERT...')\n",
    "\n",
    "# Listas para almacenar métricas durante el entrenamiento\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "train_f1_scores = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Entrenamiento por épocas\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\nÉpoca {epoch+1}/{EPOCHS}')\n",
    "    \n",
    "    # Entrenar una época\n",
    "    train_loss, train_acc, train_f1, train_precision, train_recall = train_epoch(\n",
    "        model, train_dataloader, optimizer, scheduler, device\n",
    "    )\n",
    "    \n",
    "    # Evaluar en el conjunto de validación\n",
    "    val_loss, val_acc, val_f1, val_precision, val_recall, _, _, _ = evaluate(\n",
    "        model, val_dataloader, device\n",
    "    )\n",
    "    \n",
    "    # Guardar métricas\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_f1_scores.append(val_f1)\n",
    "    \n",
    "    # Imprimir métricas\n",
    "    print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}')\n",
    "    print(f'Train Precision: {train_precision:.4f} | Train Recall: {train_recall:.4f}')\n",
    "    print(f'Val Precision: {val_precision:.4f} | Val Recall: {val_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las métricas durante el entrenamiento\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gráfico de pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "# Gráfico de precisión y F1\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.plot(train_f1_scores, label='Train F1')\n",
    "plt.plot(val_f1_scores, label='Val F1')\n",
    "plt.title('Precisión y F1 durante el entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Puntuación')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluación del Modelo en el Conjunto de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc, test_f1, test_precision, test_recall, test_conf_matrix, test_preds, test_labels = evaluate(\n",
    "    model, test_dataloader, device\n",
    ")\n",
    "\n",
    "# Imprimir métricas de evaluación\n",
    "print('Resultados en el conjunto de prueba:')\n",
    "print(f'Accuracy: {test_acc:.4f}')\n",
    "print(f'F1 Score: {test_f1:.4f}')\n",
    "print(f'Precision: {test_precision:.4f}')\n",
    "print(f'Recall: {test_recall:.4f}')\n",
    "print(f'Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(test_conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Tóxico', 'Tóxico'],\n",
    "            yticklabels=['No Tóxico', 'Tóxico'])\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar informe de clasificación detallado\n",
    "print('Informe de Clasificación:')\n",
    "print(classification_report(test_labels, test_preds, target_names=['No Tóxico', 'Tóxico']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análisis de Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar ejemplos mal clasificados\n",
    "misclassified_indices = [i for i, (pred, label) in enumerate(zip(test_preds, test_labels)) if pred != label]\n",
    "\n",
    "# Seleccionar algunos ejemplos mal clasificados para análisis\n",
    "num_examples = min(10, len(misclassified_indices))\n",
    "selected_indices = np.random.choice(misclassified_indices, num_examples, replace=False)\n",
    "\n",
    "print(f'Analizando {num_examples} ejemplos mal clasificados:')\n",
    "\n",
    "for idx in selected_indices:\n",
    "    text = X_test[idx]\n",
    "    true_label = y_test[idx]\n",
    "    pred_label = test_preds[idx]\n",
    "    \n",
    "    print('\n' + '-'*80)\n",
    "    print(f'Texto: {text}')\n",
    "    print(f'Etiqueta real: {\\' Tóxico\\' if true_label == 1 else \\'No Tóxico\\'}')\n",
    "    print(f'Predicción: {\\'Tóxico\\' if pred_label == 1 else \\'No Tóxico\\'}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Guardar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "output_dir = '../Models/bert_toxic_comments/'\n",
    "\n",
    "# Crear directorio si no existe\n",
    "import os\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Guardar modelo y tokenizador\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f'Modelo guardado en {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Función para Predicción con Nuevos Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_toxicity(text, model, tokenizer, device, max_len=128):\n",
    "    '''\n",
    "    Función para predecir si un texto es tóxico o no\n",
    "    '''\n",
    "    # Preprocesar el texto\n",
    "    cleaned_text = clean_text(text)\n",
    "    lemmatized_text = lemmatize_text(cleaned_text)\n",
    "    \n",
    "    # Tokenizar\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        lemmatized_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        return_token_type_ids=True,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Mover tensores al dispositivo\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    token_type_ids = encoding['token_type_ids'].to(device)\n",
    "    \n",
    "    # Poner el modelo en modo de evaluación\n",
    "    model.eval()\n",
    "    \n",
    "    # Desactivar cálculo de gradientes\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # Obtener logits\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Aplicar softmax para obtener probabilidades\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        \n",
    "        # Obtener predicción\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "    \n",
    "    # Convertir a valores de Python\n",
    "    prediction = preds.item()\n",
    "    probability = probs[0][prediction].item()\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'cleaned_text': cleaned_text,\n",
    "        'lemmatized_text': lemmatized_text,\n",
    "        'prediction': 'Tóxico' if prediction == 1 else 'No Tóxico',\n",
    "        'probability': probability,\n",
    "        'prediction_code': prediction\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar la función de predicción con algunos ejemplos\n",
    "test_texts = [\n",
    "    \"This is a normal comment about the weather.\",\n",
    "    \"You are an idiot and nobody likes you.\",\n",
    "    \"I disagree with your political views but respect your opinion.\",\n",
    "    \"Go kill yourself, nobody would miss you.\",\n",
    "    \"The service at this restaurant was terrible, I won't be coming back.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = predict_toxicity(text, model, tokenizer, device)\n",
    "    print('\n' + '-'*80)\n",
    "    print(f'Texto original: {result['text']}')\n",
    "    print(f'Texto limpiado: {result['cleaned_text']}')\n",
    "    print(f'Texto lematizado: {result['lemmatized_text']}')\n",
    "    print(f'Predicción: {result['prediction']}')\n",
    "    print(f'Probabilidad: {result['probability']*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook, hemos implementado un modelo avanzado para la detección de comentarios tóxicos utilizando BERT. Las principales mejoras implementadas son:\n",
    "\n",
    "1. **Preprocesamiento avanzado de texto**:\n",
    "   - Limpieza de URLs, emojis, menciones, hashtags y puntuación irrelevante\n",
    "   - Uso de lematización en lugar de stemming para preservar mejor el contexto semántico\n",
    "\n",
    "2. **Aumento de datos textuales**:\n",
    "   - Aplicación de técnicas de NLP Augment para balancear el dataset\n",
    "   - Generación de nuevas muestras para la clase minoritaria\n",
    "\n",
    "3. **Modelo BERT finetuneado**:\n",
    "   - Uso de un modelo preentrenado de BERT adaptado a la tarea de clasificación de toxicidad\n",
    "   - Implementación de técnicas de entrenamiento como learning rate scheduling\n",
    "\n",
    "4. **Análisis exhaustivo**:\n",
    "   - Evaluación detallada del rendimiento del modelo\n",
    "   - Análisis de errores para identificar áreas de mejora\n",
    "\n",
    "El modelo BERT ha demostrado un rendimiento superior al modelo Naive Bayes utilizado anteriormente, con mejoras significativas en accuracy, F1-score, precisión y recall. Esto se debe principalmente a la capacidad de BERT para capturar relaciones contextuales complejas en el texto, así como a las mejoras en el preprocesamiento y el balanceo del dataset.\n",
    "\n",
    "**Posibles mejoras futuras**:\n",
    "\n",
    "1. Experimentar con otros modelos de la familia Transformer como RoBERTa, DistilBERT o XLNet\n",
    "2. Implementar técnicas de aprendizaje por transferencia más avanzadas\n",
    "3. Explorar técnicas de ensemble combinando múltiples modelos\n",
    "4. Incorporar análisis de sentimientos como característica adicional\n",
    "5. Implementar detección multiclase para categorizar diferentes tipos de toxicidad (odio, violencia, sexual, etc.)\n",
    "\n",
    "Este modelo puede ser utilizado como parte de un sistema más amplio de moderación de contenido para identificar y filtrar comentarios tóxicos en plataformas online."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}